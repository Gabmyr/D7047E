{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 1065.1ms\n",
      "Speed: 2.0ms preprocess, 1065.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 suitcase, 964.6ms\n",
      "Speed: 2.3ms preprocess, 964.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 976.7ms\n",
      "Speed: 3.7ms preprocess, 976.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 1000.6ms\n",
      "Speed: 3.0ms preprocess, 1000.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 1026.1ms\n",
      "Speed: 2.5ms preprocess, 1026.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 1001.0ms\n",
      "Speed: 2.5ms preprocess, 1001.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 925.8ms\n",
      "Speed: 2.2ms preprocess, 925.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 932.2ms\n",
      "Speed: 3.5ms preprocess, 932.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 dining table, 867.7ms\n",
      "Speed: 3.3ms preprocess, 867.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 851.6ms\n",
      "Speed: 2.0ms preprocess, 851.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 1 in argument 0, but got float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5188\\729092301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;31m# Compute mAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m \u001b[0mmAP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_boxes_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_boxes_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"mAP: {mAP}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5188\\729092301.py\u001b[0m in \u001b[0;36mcompute_map\u001b[1;34m(gt_boxes_list, pred_boxes_list, iou_threshold)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m# Calculate AP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_ap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0map_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5188\\729092301.py\u001b[0m in \u001b[0;36mcalculate_ap\u001b[1;34m(precision, recall)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;34m\"\"\"Calculate Average Precision (AP) using the precision-recall curve.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# Add endpoints to the precision-recall curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 1 in argument 0, but got float"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Load pre-trained YOLOv9 model\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "\n",
    "# Modify last layer for car detection\n",
    "num_car_classes = 1  # Since we're detecting only cars\n",
    "model.model.anchor_vec = torch.tensor([[3.5067, 4.7690], [4.9702, 6.8688], [6.9725, 9.5452]])\n",
    "model.model.nc = num_car_classes\n",
    "model.model.n = num_car_classes + 5  # 5 is the number of default attributes (4 box coordinates + 1 objectness)\n",
    "\n",
    "# Specify the path to the 'images' folder\n",
    "folder_path = \"./images\"\n",
    "\n",
    "# Specify the output folder for processed images\n",
    "output_folder = \"./Processed images\"\n",
    "\n",
    "# Check if the output folder exists, and if not, create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# List all image files in the folder\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "\n",
    "# Select a random sample of 10 images\n",
    "selected_image_files = random.sample(image_files, 10)\n",
    "\n",
    "# Data Augmentation\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # Horizontal flips\n",
    "    iaa.Affine(rotate=(-10, 10)),  # Rotate images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0))  # Apply Gaussian blur\n",
    "])\n",
    "\n",
    "# Function to process an individual image and return the processed image\n",
    "def process_image(image_file):\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Data Augmentation\n",
    "    img_aug = seq(image=img)\n",
    "    results = model(img_aug)\n",
    "    return img_aug, results\n",
    "\n",
    "# Adjust Detection Threshold\n",
    "model.conf = 0.3  # Lowering the confidence threshold\n",
    "\n",
    "# Define function to compute precision and recall\n",
    "def compute_precision_recall(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
    "    \"\"\"Compute precision and recall for object detection.\"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    # Calculate IoU for each predicted box with ground truth boxes\n",
    "    ious = torch.zeros(len(pred_boxes), len(gt_boxes))\n",
    "    for i, pred_box in enumerate(pred_boxes):\n",
    "        for j, gt_box in enumerate(gt_boxes):\n",
    "            ious[i, j] = box_iou(pred_box, gt_box)\n",
    "\n",
    "    # Match predictions to ground truth boxes\n",
    "    for j in range(len(gt_boxes)):\n",
    "        # Find the best matching prediction for each ground truth box\n",
    "        best_iou, best_pred_idx = torch.max(ious[:, j], dim=0)\n",
    "        if best_iou >= iou_threshold:\n",
    "            true_positives += 1\n",
    "            # Remove the matched prediction to avoid double counting\n",
    "            ious[best_pred_idx, :] = -1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "\n",
    "    # Count false positives\n",
    "    false_positives = len(pred_boxes) - true_positives\n",
    "\n",
    "    # Compute precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives + 1e-6)  # Add epsilon to avoid division by zero\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-6)  # Add epsilon to avoid division by zero\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# Calculate Average Precision (AP)\n",
    "def calculate_ap(precision, recall):\n",
    "    \"\"\"Calculate Average Precision (AP) using the precision-recall curve.\"\"\"\n",
    "    # Add endpoints to the precision-recall curve\n",
    "    precision = torch.cat([torch.tensor([0.]), precision, torch.tensor([0.])])\n",
    "    recall = torch.cat([torch.tensor([0.]), recall, torch.tensor([1.])])\n",
    "\n",
    "    # Compute area under the curve (AUC)\n",
    "    ap = torch.trapz(precision, recall)\n",
    "\n",
    "    return ap\n",
    "\n",
    "# Compute mAP\n",
    "def compute_map(gt_boxes_list, pred_boxes_list, iou_threshold=0.5):\n",
    "    \"\"\"Compute mean Average Precision (mAP) for object detection.\"\"\"\n",
    "    assert len(gt_boxes_list) == len(pred_boxes_list), \"Number of ground truth and prediction lists must match.\"\n",
    "    num_classes = len(gt_boxes_list)\n",
    "\n",
    "    ap_list = []\n",
    "    for class_idx in range(num_classes):\n",
    "        gt_boxes = gt_boxes_list[class_idx]\n",
    "        pred_boxes = pred_boxes_list[class_idx]\n",
    "\n",
    "        # Compute precision and recall\n",
    "        precision, recall = compute_precision_recall(gt_boxes, pred_boxes, iou_threshold)\n",
    "\n",
    "        # Calculate AP\n",
    "        ap = calculate_ap(precision, recall)\n",
    "        ap_list.append(ap)\n",
    "\n",
    "    # Compute mAP\n",
    "    mAP = torch.mean(torch.tensor(ap_list))\n",
    "\n",
    "    return mAP\n",
    "\n",
    "# Function to get ground truth bounding boxes\n",
    "def get_ground_truth_boxes(image_file):\n",
    "    # Dummy function to get ground truth bounding boxes\n",
    "    # Replace with your actual implementation\n",
    "    return []\n",
    "\n",
    "# Process and save selected images\n",
    "gt_boxes_list = []  # List to store ground truth boxes for each class\n",
    "pred_boxes_list = []  # List to store predicted boxes for each class\n",
    "\n",
    "for image_file in selected_image_files:\n",
    "    img, results = process_image(image_file)\n",
    "    processed_image = draw_bounding_boxes(img, results)\n",
    "    output_path = os.path.join(output_folder, \"processed_\" + image_file)\n",
    "    cv2.imwrite(output_path, processed_image)\n",
    "    \n",
    "    # Get ground truth bounding boxes for the current image\n",
    "    gt_boxes = get_ground_truth_boxes(image_file)\n",
    "    gt_boxes_list.append(gt_boxes)\n",
    "    \n",
    "    # Extract predicted bounding boxes from YOLO results\n",
    "    pred_boxes = []\n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            pred_boxes.append(result.boxes.xyxy)\n",
    "    pred_boxes_list.append(pred_boxes)\n",
    "\n",
    "# Compute mAP\n",
    "mAP = compute_map(gt_boxes_list, pred_boxes_list)\n",
    "print(f\"mAP: {mAP}\")\n",
    "\n",
    "# Display example processed images\n",
    "display_example_images(output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
