{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad2c4c8-cdfe-45f0-bef9-f13a2d61f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report\n",
    "\n",
    "def preprocess_pandas(data):\n",
    "    data['Sentence'] = data['Sentence'].str.lower()\n",
    "    data['Sentence'] = data['Sentence'].replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', regex=True)                      # remove emails\n",
    "    data['Sentence'] = data['Sentence'].replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', regex=True)    # remove IP address\n",
    "    data['Sentence'] = data['Sentence'].str.replace('[^\\w\\s]','')                                                       # remove special characters\n",
    "    data['Sentence'] = data['Sentence'].replace('\\d', '', regex=True)                                                   # remove numbers\n",
    "    return data\n",
    "\n",
    "# If this is the primary file that is executed (ie not an import of another file)\n",
    "if __name__ == \"__main__\":\n",
    "    # get data, pre-process and split\n",
    "    data = pd.read_csv(\"anaconda3/Exercises/amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
    "    data.columns = ['Sentence', 'Class']\n",
    "    data['index'] = data.index                                          # add new column index\n",
    "    columns = ['index', 'Class', 'Sentence']\n",
    "    data = preprocess_pandas(data)                             # pre-process\n",
    "    training_data, validation_data, training_labels, validation_labels = train_test_split( # split the data into training, validation, and test splits\n",
    "        data['Sentence'].values.astype('U'),\n",
    "        data['Class'].values.astype('int32'),\n",
    "        test_size=0.10,\n",
    "        random_state=0,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # vectorize data using TFIDF and transform for PyTorch for scalability\n",
    "    word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), max_features=50000, max_df=0.5, use_idf=True, norm='l2')\n",
    "    training_data = word_vectorizer.fit_transform(training_data)        # transform texts to sparse matrix\n",
    "    training_data = training_data.todense()                             # convert to dense matrix for Pytorch\n",
    "    vocab_size = len(word_vectorizer.vocabulary_)\n",
    "    validation_data = word_vectorizer.transform(validation_data)\n",
    "    validation_data = validation_data.todense()\n",
    "    train_x_tensor = torch.from_numpy(np.array(training_data)).type(torch.FloatTensor)\n",
    "    train_y_tensor = torch.from_numpy(np.array(training_labels)).long()\n",
    "    validation_x_tensor = torch.from_numpy(np.array(validation_data)).type(torch.FloatTensor)\n",
    "    validation_y_tensor = torch.from_numpy(np.array(validation_labels)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b93e642-7362-4216-afe4-19f6cb69a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6930196285247803\n",
      "Epoch [2/100], Loss: 0.6882813572883606\n",
      "Epoch [3/100], Loss: 0.6833800077438354\n",
      "Epoch [4/100], Loss: 0.6780531406402588\n",
      "Epoch [5/100], Loss: 0.6721526384353638\n",
      "Epoch [6/100], Loss: 0.6655877828598022\n",
      "Epoch [7/100], Loss: 0.6583189368247986\n",
      "Epoch [8/100], Loss: 0.6503648161888123\n",
      "Epoch [9/100], Loss: 0.6417384147644043\n",
      "Epoch [10/100], Loss: 0.6324566006660461\n",
      "Epoch [11/100], Loss: 0.6225454807281494\n",
      "Epoch [12/100], Loss: 0.6120348572731018\n",
      "Epoch [13/100], Loss: 0.6009528040885925\n",
      "Epoch [14/100], Loss: 0.5893341302871704\n",
      "Epoch [15/100], Loss: 0.5772116184234619\n",
      "Epoch [16/100], Loss: 0.5646151900291443\n",
      "Epoch [17/100], Loss: 0.5515804886817932\n",
      "Epoch [18/100], Loss: 0.5381439328193665\n",
      "Epoch [19/100], Loss: 0.5243374109268188\n",
      "Epoch [20/100], Loss: 0.5102003812789917\n",
      "Epoch [21/100], Loss: 0.49577242136001587\n",
      "Epoch [22/100], Loss: 0.4810952842235565\n",
      "Epoch [23/100], Loss: 0.46621203422546387\n",
      "Epoch [24/100], Loss: 0.4511665105819702\n",
      "Epoch [25/100], Loss: 0.4360002875328064\n",
      "Epoch [26/100], Loss: 0.4207606911659241\n",
      "Epoch [27/100], Loss: 0.4054969549179077\n",
      "Epoch [28/100], Loss: 0.3902551531791687\n",
      "Epoch [29/100], Loss: 0.37508147954940796\n",
      "Epoch [30/100], Loss: 0.3600217401981354\n",
      "Epoch [31/100], Loss: 0.3451198935508728\n",
      "Epoch [32/100], Loss: 0.33042049407958984\n",
      "Epoch [33/100], Loss: 0.3159654140472412\n",
      "Epoch [34/100], Loss: 0.30179306864738464\n",
      "Epoch [35/100], Loss: 0.2879367470741272\n",
      "Epoch [36/100], Loss: 0.2744310200214386\n",
      "Epoch [37/100], Loss: 0.2613028287887573\n",
      "Epoch [38/100], Loss: 0.24857699871063232\n",
      "Epoch [39/100], Loss: 0.23627348244190216\n",
      "Epoch [40/100], Loss: 0.2244098037481308\n",
      "Epoch [41/100], Loss: 0.2129991054534912\n",
      "Epoch [42/100], Loss: 0.20204973220825195\n",
      "Epoch [43/100], Loss: 0.1915670484304428\n",
      "Epoch [44/100], Loss: 0.18155145645141602\n",
      "Epoch [45/100], Loss: 0.172003835439682\n",
      "Epoch [46/100], Loss: 0.16291923820972443\n",
      "Epoch [47/100], Loss: 0.15428923070430756\n",
      "Epoch [48/100], Loss: 0.14610472321510315\n",
      "Epoch [49/100], Loss: 0.13835501670837402\n",
      "Epoch [50/100], Loss: 0.13102754950523376\n",
      "Epoch [51/100], Loss: 0.12410830706357956\n",
      "Epoch [52/100], Loss: 0.11758144944906235\n",
      "Epoch [53/100], Loss: 0.1114308089017868\n",
      "Epoch [54/100], Loss: 0.10564008355140686\n",
      "Epoch [55/100], Loss: 0.10019230842590332\n",
      "Epoch [56/100], Loss: 0.09507070481777191\n",
      "Epoch [57/100], Loss: 0.0902583971619606\n",
      "Epoch [58/100], Loss: 0.0857388973236084\n",
      "Epoch [59/100], Loss: 0.08149541169404984\n",
      "Epoch [60/100], Loss: 0.07751219719648361\n",
      "Epoch [61/100], Loss: 0.07377424091100693\n",
      "Epoch [62/100], Loss: 0.07026634365320206\n",
      "Epoch [63/100], Loss: 0.06697463244199753\n",
      "Epoch [64/100], Loss: 0.06388547271490097\n",
      "Epoch [65/100], Loss: 0.060985758900642395\n",
      "Epoch [66/100], Loss: 0.05826329439878464\n",
      "Epoch [67/100], Loss: 0.05570646747946739\n",
      "Epoch [68/100], Loss: 0.05330432951450348\n",
      "Epoch [69/100], Loss: 0.051047008484601974\n",
      "Epoch [70/100], Loss: 0.04892459139227867\n",
      "Epoch [71/100], Loss: 0.04692789539694786\n",
      "Epoch [72/100], Loss: 0.04504846781492233\n",
      "Epoch [73/100], Loss: 0.04327865689992905\n",
      "Epoch [74/100], Loss: 0.04161111265420914\n",
      "Epoch [75/100], Loss: 0.0400388278067112\n",
      "Epoch [76/100], Loss: 0.03855527937412262\n",
      "Epoch [77/100], Loss: 0.03715471550822258\n",
      "Epoch [78/100], Loss: 0.035831332206726074\n",
      "Epoch [79/100], Loss: 0.0345800518989563\n",
      "Epoch [80/100], Loss: 0.03339629992842674\n",
      "Epoch [81/100], Loss: 0.03227557986974716\n",
      "Epoch [82/100], Loss: 0.03121352382004261\n",
      "Epoch [83/100], Loss: 0.03020639903843403\n",
      "Epoch [84/100], Loss: 0.029250673949718475\n",
      "Epoch [85/100], Loss: 0.028343036770820618\n",
      "Epoch [86/100], Loss: 0.027480455115437508\n",
      "Epoch [87/100], Loss: 0.026660103350877762\n",
      "Epoch [88/100], Loss: 0.025879288092255592\n",
      "Epoch [89/100], Loss: 0.02513546124100685\n",
      "Epoch [90/100], Loss: 0.024426477029919624\n",
      "Epoch [91/100], Loss: 0.023750100284814835\n",
      "Epoch [92/100], Loss: 0.02310430444777012\n",
      "Epoch [93/100], Loss: 0.022487329319119453\n",
      "Epoch [94/100], Loss: 0.021897509694099426\n",
      "Epoch [95/100], Loss: 0.021333228796720505\n",
      "Epoch [96/100], Loss: 0.020793002098798752\n",
      "Epoch [97/100], Loss: 0.02027544006705284\n",
      "Epoch [98/100], Loss: 0.019779261201620102\n",
      "Epoch [99/100], Loss: 0.019303234294056892\n",
      "Epoch [100/100], Loss: 0.018846269696950912\n",
      "Chatbot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  This does not work!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: It seems like you're expressing a negative sentiment.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Im so happy with the support i have got from you!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: It seems like you're expressing a positive sentiment.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network architecture\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "input_size = vocab_size\n",
    "hidden_size = 128\n",
    "output_size = 2\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x_tensor)\n",
    "    loss = criterion(output, train_y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Define the chatbot\n",
    "def chatbot():\n",
    "    print(\"Chatbot: Hello! How can I assist you today?\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            # Preprocess user input and convert to tensor\n",
    "            user_input = word_vectorizer.transform([user_input])\n",
    "            user_input = torch.tensor(user_input.todense(), dtype=torch.float32)\n",
    "            # Analyze user input using the trained model\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(user_input)\n",
    "                predicted_class = torch.argmax(output, dim=1).item()\n",
    "            if predicted_class == 0:\n",
    "                print(\"Chatbot: It seems like you're expressing a negative sentiment.\")\n",
    "            else:\n",
    "                print(\"Chatbot: It seems like you're expressing a positive sentiment.\")\n",
    "\n",
    "# Start the chatbot\n",
    "chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
