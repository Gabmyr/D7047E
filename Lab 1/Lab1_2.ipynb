{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Testing of the method\n"
      ],
      "metadata": {
        "id": "HKopSdSZIEHa"
      },
      "id": "HKopSdSZIEHa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a240446-0ae1-4973-b8f1-98764745ad30",
      "metadata": {
        "id": "4a240446-0ae1-4973-b8f1-98764745ad30",
        "outputId": "e6974138-c762-4a59-9879-0ebf5120104a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "#Doesent work download manually instead\n",
        "\n",
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bfc8bb2-64ec-463c-abaa-906896f57136",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5bfc8bb2-64ec-463c-abaa-906896f57136",
        "outputId": "54c7b524-9005-4c92-95ba-64e7e470e3a5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115393 \n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n",
            "All characters in dataset\n",
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "There are  65  unique characters\n"
          ]
        }
      ],
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"length of dataset in characters: \", len(text),\"\\n\")\n",
        "print(text[:1000])\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print('All characters in dataset')\n",
        "print(''.join(chars))\n",
        "print('There are ',vocab_size,' unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28a17e4-e68e-4587-9f04-d097e1ded55e",
      "metadata": {
        "id": "c28a17e4-e68e-4587-9f04-d097e1ded55e",
        "outputId": "0b9036f9-3d11-4198-e206-0db93e066c9c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[32, 43, 57, 58, 1, 57, 58, 56, 47, 52, 45, 1, 4, 1, 41, 46, 39, 56, 57]\n",
            "Test string & chars\n"
          ]
        }
      ],
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars) }\n",
        "itos = {i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]          #Endcoder: string --> list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l])  #Decoder: list of integers --> string\n",
        "\n",
        "testString = \"Test string & chars\"\n",
        "print(encode(testString))\n",
        "print(decode(encode(testString)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fcadef6-a6a6-4b1e-bf0c-78582c790f8e",
      "metadata": {
        "id": "6fcadef6-a6a6-4b1e-bf0c-78582c790f8e",
        "outputId": "67f0dde0-54a5-41ee-e98b-6c4c04bb112b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115393]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbb23e9-5836-43d7-9cb8-4885ba43737e",
      "metadata": {
        "id": "afbb23e9-5836-43d7-9cb8-4885ba43737e"
      },
      "outputs": [],
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e9ef94-2eca-4bb9-99f8-65fdfaa48550",
      "metadata": {
        "id": "19e9ef94-2eca-4bb9-99f8-65fdfaa48550",
        "outputId": "c766a1b4-45d8-408f-ac43-2c4ba237f27b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1bdf29-a99e-475f-ba59-54cebfc17b38",
      "metadata": {
        "id": "7a1bdf29-a99e-475f-ba59-54cebfc17b38",
        "outputId": "9526cf73-e418-4328-e16f-2fb272a26fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 1, 39, 45, 39, 47, 52, 57, 58],\n",
            "        [26, 53,  1, 51, 39, 58, 58, 43],\n",
            "        [ 1, 61, 43, 43, 54, 47, 52, 45],\n",
            "        [63,  6,  7,  7,  0,  0, 13, 33]])\n",
            "targets\n",
            "torch.Size([4, 8])\n",
            "tensor([[39, 45, 39, 47, 52, 57, 58,  1],\n",
            "        [53,  1, 51, 39, 58, 58, 43, 56],\n",
            "        [61, 43, 43, 54, 47, 52, 45,  1],\n",
            "        [ 6,  7,  7,  0,  0, 13, 33, 18]])\n",
            "-----\n",
            "Batch:  0\n",
            "when input is [1] the target: 39\n",
            "when input is [1, 39] the target: 45\n",
            "when input is [1, 39, 45] the target: 39\n",
            "when input is [1, 39, 45, 39] the target: 47\n",
            "when input is [1, 39, 45, 39, 47] the target: 52\n",
            "when input is [1, 39, 45, 39, 47, 52] the target: 57\n",
            "when input is [1, 39, 45, 39, 47, 52, 57] the target: 58\n",
            "when input is [1, 39, 45, 39, 47, 52, 57, 58] the target: 1\n",
            "Batch:  1\n",
            "when input is [26] the target: 53\n",
            "when input is [26, 53] the target: 1\n",
            "when input is [26, 53, 1] the target: 51\n",
            "when input is [26, 53, 1, 51] the target: 39\n",
            "when input is [26, 53, 1, 51, 39] the target: 58\n",
            "when input is [26, 53, 1, 51, 39, 58] the target: 58\n",
            "when input is [26, 53, 1, 51, 39, 58, 58] the target: 43\n",
            "when input is [26, 53, 1, 51, 39, 58, 58, 43] the target: 56\n",
            "Batch:  2\n",
            "when input is [1] the target: 61\n",
            "when input is [1, 61] the target: 43\n",
            "when input is [1, 61, 43] the target: 43\n",
            "when input is [1, 61, 43, 43] the target: 54\n",
            "when input is [1, 61, 43, 43, 54] the target: 47\n",
            "when input is [1, 61, 43, 43, 54, 47] the target: 52\n",
            "when input is [1, 61, 43, 43, 54, 47, 52] the target: 45\n",
            "when input is [1, 61, 43, 43, 54, 47, 52, 45] the target: 1\n",
            "Batch:  3\n",
            "when input is [63] the target: 6\n",
            "when input is [63, 6] the target: 7\n",
            "when input is [63, 6, 7] the target: 7\n",
            "when input is [63, 6, 7, 7] the target: 0\n",
            "when input is [63, 6, 7, 7, 0] the target: 0\n",
            "when input is [63, 6, 7, 7, 0, 0] the target: 13\n",
            "when input is [63, 6, 7, 7, 0, 0, 13] the target: 33\n",
            "when input is [63, 6, 7, 7, 0, 0, 13, 33] the target: 18\n"
          ]
        }
      ],
      "source": [
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) -block_size, (batch_size,)) #random offset in the dataset from 0 to len(data)-block_size\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "xb,yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('-----')\n",
        "\n",
        "for b in range(batch_size):\n",
        "    print('Batch: ', b)\n",
        "    for t in range(block_size):\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full finished code\n",
        "\n",
        "Start here:"
      ],
      "metadata": {
        "id": "1aSzl9qnIKtx"
      },
      "id": "1aSzl9qnIKtx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8102dd6a-005a-48c2-8845-c1f0bcdcaf26",
      "metadata": {
        "id": "8102dd6a-005a-48c2-8845-c1f0bcdcaf26"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cF4UTvYPs6rq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF4UTvYPs6rq",
        "outputId": "6b051977-9cf9-42e4-8885-89028920f5af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115393 \n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n",
            "All characters in dataset\n",
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "There are  65  unique characters\n"
          ]
        }
      ],
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"length of dataset in characters: \", len(text),\"\\n\")\n",
        "print(text[:1000])\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print('All characters in dataset')\n",
        "print(''.join(chars))\n",
        "print('There are ',vocab_size,' unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jyxDbOi7tYgM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyxDbOi7tYgM",
        "outputId": "aff75e7f-6e35-4529-f5d2-ba14033ebe51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[32, 43, 57, 58, 1, 57, 58, 56, 47, 52, 45, 1, 4, 1, 41, 46, 39, 56, 57]\n",
            "Test string & chars\n",
            "torch.Size([1115393]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars) }\n",
        "itos = {i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]          #Endcoder: string --> list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l])  #Decoder: list of integers --> string\n",
        "\n",
        "testString = \"Test string & chars\"\n",
        "print(encode(testString))\n",
        "print(decode(encode(testString)))\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])\n",
        "\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b69a4862-6fe4-473d-98b6-c13931f12bc2",
      "metadata": {
        "id": "b69a4862-6fe4-473d-98b6-c13931f12bc2"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters Currently to big for google colab\n",
        "batch_size = 64       #was 32\n",
        "block_size = 128        #was 8\n",
        "max_iters = 5000      #was 5000\n",
        "eval_interval = 200   #was 300\n",
        "learning_rate = 3e-4  #was 1e-3\n",
        "eval_iters = 200      #was 200\n",
        "n_embd = 256           #was 32\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "859a64a4-087c-4a46-947f-6641f92a1c43",
      "metadata": {
        "id": "859a64a4-087c-4a46-947f-6641f92a1c43"
      },
      "outputs": [],
      "source": [
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) -block_size, (batch_size,)) #random offset in the dataset from 0 to len(data)-block_size\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    m.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = m(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    m.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea89a67-ffac-4beb-9079-c0fa772fa7f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eea89a67-ffac-4beb-9079-c0fa772fa7f7",
        "outputId": "ef2accf5-f39f-4be1-ed04-fd11d5a0c1de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.5779, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class Head(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril',torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout) #Randomly shuts of some neurons to prevent overfitting\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(num_heads * head_size, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)   #Randomly shuts of some neurons to prevent overfitting\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "          nn.Linear(n_embd,4 * n_embd),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(4 * n_embd, n_embd),\n",
        "          nn.Dropout(dropout),   #Randomly shuts of some neurons to prevent overfitting\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self,n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))    #Residual connections is why we keep x\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size,n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (Batch,Time) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) #(Batch, Time, Chanel) 3-dimensionall tensor\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T))  # (T,C)\n",
        "        x = tok_emb + pos_emb   #(B,T,C)\n",
        "        x = self.blocks(x)       #(B,T,C)\n",
        "        logits =  self.lm_head(x) #(B,T,voacb_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits=logits.view(B*T, C) #Fits better with pytorch\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "xb,yb = get_batch('train')\n",
        "\n",
        "m = BigramLanguageModel()\n",
        "logits, loss = m(xb,yb)\n",
        "print(loss)\n",
        "\n",
        "#idx = torch.zeros((1,1), dtype=torch.long)\n",
        "#print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72790b9e-0c33-494a-99bf-588d170535e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "72790b9e-0c33-494a-99bf-588d170535e4",
        "outputId": "82ae5474-b91d-410b-eecf-27212fcfcc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step  0: train loss 4.5740, val loss 4.5672\n",
            "step  200: train loss 2.4228, val loss 2.4485\n",
            "step  400: train loss 2.1800, val loss 2.2149\n",
            "step  600: train loss 1.9958, val loss 2.0626\n",
            "step  800: train loss 1.8524, val loss 1.9601\n",
            "step  1000: train loss 1.7507, val loss 1.8874\n",
            "step  1200: train loss 1.6736, val loss 1.8306\n",
            "step  1400: train loss 1.6134, val loss 1.7824\n",
            "step  1600: train loss 1.5693, val loss 1.7486\n",
            "step  1800: train loss 1.5273, val loss 1.7158\n",
            "step  2000: train loss 1.5001, val loss 1.6967\n",
            "step  2200: train loss 1.4691, val loss 1.6642\n",
            "step  2400: train loss 1.4443, val loss 1.6507\n",
            "step  2600: train loss 1.4228, val loss 1.6271\n",
            "step  2800: train loss 1.4054, val loss 1.6171\n",
            "step  3000: train loss 1.3896, val loss 1.5939\n",
            "step  3200: train loss 1.3730, val loss 1.5903\n",
            "step  3400: train loss 1.3587, val loss 1.5727\n",
            "step  3600: train loss 1.3478, val loss 1.5778\n",
            "step  3800: train loss 1.3339, val loss 1.5657\n",
            "step  4000: train loss 1.3235, val loss 1.5519\n",
            "step  4200: train loss 1.3097, val loss 1.5449\n",
            "step  4400: train loss 1.3012, val loss 1.5453\n",
            "step  4600: train loss 1.2929, val loss 1.5343\n",
            "step  4800: train loss 1.2882, val loss 1.5340\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step  {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cee6797-927e-4e9e-828c-47c87fd03e7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cee6797-927e-4e9e-828c-47c87fd03e7b",
        "outputId": "0b43f101-c09a-42b1-f0cb-b50310fc0864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0]])\n",
            "\n",
            "\n",
            "MENENIUS:\n",
            "Mercy, one dreams; why, counsel the hopesition.\n",
            "\n",
            "CORIOLANUS:\n",
            "Yet be bankle, thy heaven worse,\n",
            "Your twos are me, you comed's tongue rosen:\n",
            "Hosteff, each your soul means with our poorsue.\n",
            "\n",
            "DORSET:\n",
            "Not should usband and I hard, with to Poluck this Engling;\n",
            "My lies: this over are not, for our serve\n",
            "My honest at his name of ponior tongue,\n",
            "Some remied with some and from me and sooth,\n",
            "I come him to give him.\n",
            "\n",
            "HENRY Provingman:\n",
            "The consman's soul, what honour thank his good were,\n",
            "To other sol\n"
          ]
        }
      ],
      "source": [
        "#Generate from model\n",
        "context = torch.zeros((1,1), dtype=torch.long)\n",
        "\n",
        "print(context)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}